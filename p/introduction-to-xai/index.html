<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content="Introduction to XAI(eXplainable AI) 최근 많은 산업에서 딥러닝을 적용을 시도하고 있습니다. 하지만 모델의 결과가 어떤 과정을 통해서 그런 예측을 했는지 해석하기 어려운 &lsquo;블랙박스&rsquo; 문제는 딥러닝 적용을 blocking하는 큰 요인입니다.\n예를 들어 신규 대출을 받으려는 고객이 있습니다. 은행에서는 이 고객이 대출을 잘 갚을 수 있을지에 대해 심사를 하고 대출을 승인을 결정합니다. 이 은행에서는 딥러닝 모델을 이용해 고객들의 대출 심사를 합니다. 모델은 이 고객에게 대출을 거절했습니다. 고객과 대출 담당자는 대출이 거절된 이유가 고객의 나이, 직업 등 어떤 이유로 대출이 거절 되었는지 알고 싶습니다. 여기서 문제가 발생합니다. 우리는 딥러닝 모델의 결정을 해석할 수가 없습니다. 이러한 해석을 할 수 없다는 단점은 여러 산업에서 딥러닝 모델의 적용을 망설이게 합니다.\n"><title>Introduction to XAI</title>
<link rel=canonical href=https://aiden-jeon.github.io/blog/p/introduction-to-xai/><link rel=stylesheet href=/blog/scss/style.min.663803bebe609202d5b39d848f2d7c2dc8b598a2d879efa079fa88893d29c49c.css><meta property='og:title' content="Introduction to XAI"><meta property='og:description' content="Introduction to XAI(eXplainable AI) 최근 많은 산업에서 딥러닝을 적용을 시도하고 있습니다. 하지만 모델의 결과가 어떤 과정을 통해서 그런 예측을 했는지 해석하기 어려운 &lsquo;블랙박스&rsquo; 문제는 딥러닝 적용을 blocking하는 큰 요인입니다.\n예를 들어 신규 대출을 받으려는 고객이 있습니다. 은행에서는 이 고객이 대출을 잘 갚을 수 있을지에 대해 심사를 하고 대출을 승인을 결정합니다. 이 은행에서는 딥러닝 모델을 이용해 고객들의 대출 심사를 합니다. 모델은 이 고객에게 대출을 거절했습니다. 고객과 대출 담당자는 대출이 거절된 이유가 고객의 나이, 직업 등 어떤 이유로 대출이 거절 되었는지 알고 싶습니다. 여기서 문제가 발생합니다. 우리는 딥러닝 모델의 결정을 해석할 수가 없습니다. 이러한 해석을 할 수 없다는 단점은 여러 산업에서 딥러닝 모델의 적용을 망설이게 합니다.\n"><meta property='og:url' content='https://aiden-jeon.github.io/blog/p/introduction-to-xai/'><meta property='og:site_name' content="Aiden's Camp"><meta property='og:type' content='article'><meta property='article:section' content='Post'><meta property='article:tag' content='xai'><meta property='article:published_time' content='2021-03-31T00:00:00+00:00'><meta property='article:modified_time' content='2021-03-31T00:00:00+00:00'><meta name=twitter:title content="Introduction to XAI"><meta name=twitter:description content="Introduction to XAI(eXplainable AI) 최근 많은 산업에서 딥러닝을 적용을 시도하고 있습니다. 하지만 모델의 결과가 어떤 과정을 통해서 그런 예측을 했는지 해석하기 어려운 &lsquo;블랙박스&rsquo; 문제는 딥러닝 적용을 blocking하는 큰 요인입니다.\n예를 들어 신규 대출을 받으려는 고객이 있습니다. 은행에서는 이 고객이 대출을 잘 갚을 수 있을지에 대해 심사를 하고 대출을 승인을 결정합니다. 이 은행에서는 딥러닝 모델을 이용해 고객들의 대출 심사를 합니다. 모델은 이 고객에게 대출을 거절했습니다. 고객과 대출 담당자는 대출이 거절된 이유가 고객의 나이, 직업 등 어떤 이유로 대출이 거절 되었는지 알고 싶습니다. 여기서 문제가 발생합니다. 우리는 딥러닝 모델의 결정을 해석할 수가 없습니다. 이러한 해석을 할 수 없다는 단점은 여러 산업에서 딥러닝 모델의 적용을 망설이게 합니다.\n"><link rel="shortcut icon" href=/blog/icons/favicon.ico><script async src="https://www.googletagmanager.com/gtag/js?id=G-419F58RW9W"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-419F58RW9W")}</script></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label="Toggle Menu">
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/blog/><img src=/blog/imgs/avatar_hu6933059792947527008.png width=300 height=300 class=site-logo loading=lazy alt=Avatar>
</a><span class=emoji>🔥</span></figure><div class=site-meta><h1 class=site-name><a href=/blog>Aiden's Camp</a></h1><h2 class=site-description>Welcome to Aiden's Camp</h2></div></header><ol class=menu-social><li><a href=https://github.com/Aiden-Jeon target=_blank title=GitHub rel=me><svg class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li><li><a href=https://www.linkedin.com/in/jongseob-jeon/ target=_blank title=Linkedin rel=me><svg fill="#000" height="800" width="800" id="Layer_1" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 310 310"><g id="XMLID_801_"><path id="XMLID_802_" d="M72.16 99.73H9.927c-2.762.0-5 2.239-5 5v199.928c0 2.762 2.238 5 5 5H72.16c2.762.0 5-2.238 5-5V104.73c0-2.76100000000001-2.238-5-5-5z"/><path id="XMLID_803_" d="M41.066.341C18.422.341.0 18.743.0 41.362.0 63.991 18.422 82.4 41.066 82.4c22.626.0 41.033-18.41 41.033-41.038C82.1 18.743 63.692.341 41.066.341z"/><path id="XMLID_804_" d="M230.454 94.761c-24.995.0-43.472 10.745-54.679 22.954V104.73c0-2.761-2.238-5-5-5h-59.599c-2.762.0-5 2.239-5 5v199.928c0 2.762 2.238 5 5 5h62.097c2.762.0 5-2.238 5-5V205.74c0-33.333 9.054-46.319 32.29-46.319 25.306.0 27.317 20.818 27.317 48.034v97.204c0 2.762 2.238 5 5 5H305c2.762.0 5-2.238 5-5V194.995C310 145.43 300.549 94.761 230.454 94.761z"/></g></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/blog/><svg class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>Home</span></a></li><li><a href=/blog/categories><svg class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg>
<span>Categories</span></a></li><li><a href=/blog/tags><svg class="icon icon-tabler icon-tabler-tag" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11 3l9 9a1.5 1.5.0 010 2l-6 6a1.5 1.5.0 01-2 0L3 11V7a4 4 0 014-4h4"/><circle cx="9" cy="9" r="2"/></svg>
<span>Tags</span></a></li><li><a href=/blog/links/><svg class="icon icon-tabler icon-tabler-link" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M10 14a3.5 3.5.0 005 0l4-4a3.5 3.5.0 00-5-5l-.5.5"/><path d="M14 10a3.5 3.5.0 00-5 0l-4 4a3.5 3.5.0 005 5l.5-.5"/></svg>
<span>Links</span></a></li><li><a href=/blog/search/><svg class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
<span>Search</span></a></li><li><a href=/blog/archives/><svg class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg>
<span>Archives</span></a></li><li class=menu-bottom-section><ol class=menu><li id=dark-mode-toggle><svg class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>Dark Mode</span></li></ol></li></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">Table of contents</h2><div class=widget--toc><nav id=TableOfContents><ul><li><a href=#introduction-to-xaiexplainable-ai>Introduction to XAI(eXplainable AI)</a></li><li><a href=#interpretable-vs-accurate-trade-off>Interpretable vs Accurate Trade-off</a></li><li><a href=#대리-분석-surrogate-analysis>대리 분석 (Surrogate Analysis)</a><ul><li><a href=#글로벌-대리-분석-global-surrogate-analysis>글로벌 대리 분석 (Global Surrogate Analysis)</a><ul><li><a href=#글로벌-대리-분석-수행-과정>글로벌 대리 분석 수행 과정</a></li><li><a href=#장점>장점</a></li><li><a href=#단점>단점</a></li></ul></li><li><a href=#로컬-대리-분석-local-surrogate-analysis>로컬 대리 분석 (Local Surrogate Analysis)</a><ul><li><a href=#로컬-대리-분석-방법>로컬 대리 분석 방법</a></li><li><a href=#장점-1>장점</a></li><li><a href=#단점-1>단점</a></li></ul></li></ul></li><li><a href=#reference>Reference</a></li></ul></nav></div></section></aside><main class="main full-width"><article class=main-article><header class=article-header><div class=article-details><header class=article-category><a href=/blog/categories/machine-learning/>Machine-Learning</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/blog/p/introduction-to-xai/>Introduction to XAI</a></h2></div><footer class=article-time><div><svg class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published>Mar 31, 2021</time></div><div><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<time class=article-time--reading>4 minute read</time></div></footer></div></header><section class=article-content><h2 id=introduction-to-xaiexplainable-ai><a href=#introduction-to-xaiexplainable-ai class=header-anchor></a>Introduction to XAI(eXplainable AI)</h2><p>최근 많은 산업에서 딥러닝을 적용을 시도하고 있습니다. 하지만 모델의 결과가 어떤 과정을 통해서 그런 예측을 했는지 해석하기 어려운 &lsquo;블랙박스&rsquo; 문제는 딥러닝 적용을 blocking하는 큰 요인입니다.</p><p><img src=/imgs/xai/xai-1.png loading=lazy alt=그림-1></p><p>예를 들어 신규 대출을 받으려는 고객이 있습니다. 은행에서는 이 고객이 대출을 잘 갚을 수 있을지에 대해 심사를 하고 대출을 승인을 결정합니다. 이 은행에서는 딥러닝 모델을 이용해 고객들의 대출 심사를 합니다. 모델은 이 고객에게 대출을 거절했습니다. 고객과 대출 담당자는 대출이 거절된 이유가 고객의 나이, 직업 등 어떤 이유로 대출이 거절 되었는지 알고 싶습니다. 여기서 문제가 발생합니다. 우리는 딥러닝 모델의 결정을 해석할 수가 없습니다. 이러한 해석을 할 수 없다는 단점은 여러 산업에서 딥러닝 모델의 적용을 망설이게 합니다.</p><h2 id=interpretable-vs-accurate-trade-off><a href=#interpretable-vs-accurate-trade-off class=header-anchor></a>Interpretable vs Accurate Trade-off</h2><p><img src=/imgs/xai/xai-2.png loading=lazy alt=그림-2></p><p>그럼 이런 의문이 들 수 도 있습니다. 해석이 힘든 딥러닝 모델 대신 해석하기 쉬운 선형회귀분석 같은 모델을 사용하면 되지 않을까? 하지만 복잡한 모델과 간단한 모델, 이 두 모델 사이에는 Trade-off 가 있습니다. 해석이 쉬운 모델들은 정확도가 떨어지며, 높은 정확도를 보이는 모델은 해석이 어렵습니다.</p><p>그럼 해석하기도 쉽고 정확도도 높은 모델을 만들면 되지 않을까요? 방법은 두가지가 있습니다. 해석이 쉬운 모델의 정확도를 높이는 방법과 정확도가 높은 모델의 해석 가능성을 높이는 방법입니다. 그리고 최근 논문들을 보면 2번의 방법을 연구하는 추세입니다.</p><p><img src=/imgs/xai/xai-3.png loading=lazy alt=그림-3></p><ol><li>해석이 쉬운 모델의 정확도를 높이는 방법</li></ol><p><img src=/imgs/xai/xai-4.png loading=lazy alt=그림-4></p><ol start=2><li>정확도가 높은 모델의 해석 가능성을 높이는 방법</li></ol><h2 id=대리-분석-surrogate-analysis><a href=#%eb%8c%80%eb%a6%ac-%eb%b6%84%ec%84%9d-surrogate-analysis class=header-anchor></a>대리 분석 (Surrogate Analysis)</h2><p>Surrogate Analysis를 우리 말로 하면 대리 분석입니다. 즉, 해석이 어려운 모델을 바로 해석하지 않고 해석 가능한 대리 모델을 만들고 이를 이용해 모델의 예측 결과를 해석합니다.</p><h3 id=글로벌-대리-분석-global-surrogate-analysis><a href=#%ea%b8%80%eb%a1%9c%eb%b2%8c-%eb%8c%80%eb%a6%ac-%eb%b6%84%ec%84%9d-global-surrogate-analysis class=header-anchor></a>글로벌 대리 분석 (Global Surrogate Analysis)</h3><p>글로벌 대리 분석이란 전체 학습 데이터를 사용해 블랙박스 함수 f를 따라하는 유사함수 g를 만들고 g를 해석 가능하도록 변조하는 방법을 말합니다.</p><h4 id=글로벌-대리-분석-수행-과정><a href=#%ea%b8%80%eb%a1%9c%eb%b2%8c-%eb%8c%80%eb%a6%ac-%eb%b6%84%ec%84%9d-%ec%88%98%ed%96%89-%ea%b3%bc%ec%a0%95 class=header-anchor></a>글로벌 대리 분석 수행 과정</h4><ol><li>데이터 집합 X를 선택합니다. 이 때 집합은 학습 데이터 전체 또는 일부입니다.</li><li>선택한 데이터 집합 X에 대해 블랙박스 모델 f의 예측 결과를 구합니다. 이 집합과 예측 값은 해석가능한 모델을 fit 시키기 위한 데이터셋으로 사용됩니다.</li><li>해석 가능한 모델(g)을 고릅니다.</li><li>해석 가능한 모델을 2번에서 만든 데이터셋을 이용해 학습합니다.</li><li>데이터 X에 대하여 모델 f가 예측한 결과(2)와 모델 g의 예측 결과를 비교하면서 두 모델이 최대한 유사한 결과를 내도록 튜닝합니다.</li><li>설명 가능한 모델 g을 이용해 블랙박스 모델(f)을 해석합니다.</li></ol><h4 id=장점><a href=#%ec%9e%a5%ec%a0%90 class=header-anchor></a>장점</h4><ol><li>유연함(Flexible)<ul><li>모든 해석 가능한 모델에 사용할 수 있다.</li><li>모든 블랙박스 모델에 사용할 수 있다.</li><li>예를 들어, 선형분석이 편한 이용자와 의사결정나무가 편한 이용자가 있을 때, 한 블랙박스 모델을 선형분석, 의사결정나무 로 대리 분석 모델을 만들 수 있다.</li></ul></li><li>직관적(Intuitive)<ul><li>쉽게 실행할 수 있다.</li><li>쉽게 설명할 수 있다.</li></ul></li><li>평가의 용이<ul><li>R-Squared 척도와 같이 대리분석 모델이 얼마나 블랙박스 모델을 잘 설명했는지 알 수 있다.</li></ul></li></ol><h4 id=단점><a href=#%eb%8b%a8%ec%a0%90 class=header-anchor></a>단점</h4><ol><li>모델에 대한 결론을 낼 수는 있지만, 데이터에 대한 결론을 낼 수는 없다.</li><li>얼마나 대리 분석 모델을 fitting 시켜야 하는지 알 수 없다.</li><li>대리 분석 모델로 선택한 모델의 모든 장점과 단점이 따라온다.</li></ol><h3 id=로컬-대리-분석-local-surrogate-analysis><a href=#%eb%a1%9c%ec%bb%ac-%eb%8c%80%eb%a6%ac-%eb%b6%84%ec%84%9d-local-surrogate-analysis class=header-anchor></a>로컬 대리 분석 (Local Surrogate Analysis)</h3><p>글로벌 대리 분석에서 블랙박스 모델을 해석하려는 것과 반대로 로컬 대리 분석은 개별적인 예측을 설명하기 위한 방법입니다. 로컬 대리 분석에는 모델과 관련 없이(Model-Agnostic) 사용 할 수 있는 방법과 특정한 모델에서(model-type-specific) 사용할 수 있는 방법이 있습니다. LIME(Local Interpretable model-agnostic explanations)은 대표적인 모델과 관련 없이 사용할 수 있는 로컬 대리 분석 방법입니다. 특정한 모델에서 사용하는 방법은 DeepLIFT 등이 있습니다.</p><h4 id=로컬-대리-분석-방법><a href=#%eb%a1%9c%ec%bb%ac-%eb%8c%80%eb%a6%ac-%eb%b6%84%ec%84%9d-%eb%b0%a9%eb%b2%95 class=header-anchor></a>로컬 대리 분석 방법</h4><ol><li>블랙박스 모델 예측을 설명하고자 하는 instance (x)를 하나 선택합니다.</li><li>데이터를 섞어(perturb) 새로운 데이터 집합(x&rsquo;)을 만듭니다.</li><li>생성된 데이터 집합(x&rsquo;)을 해석하려는 모델에 넣어 예측 값f(x&rsquo;)을 계산합니다. 생성된 데이터와 예측 값은 대리 분석 모델의 데이터로 사용됩니다.</li><li>정의된 거리에 따라 새로운 데이터의 가중치(w)를 계산합니다.</li><li>가중치를 이용해 해석 가능한 모델을 학습합니다. g(f, x&rsquo;, w)</li><li>로컬 모델을 이용해 예측을 설명합니다.</li></ol><h4 id=장점-1><a href=#%ec%9e%a5%ec%a0%90-1 class=header-anchor></a>장점</h4><ol><li>설명이 선택적이고 대조적이다.<ul><li>LASSO나 짧은 트리를 이용하면 변수들을 선택할 수 있고 설명을 +,- 로 대조적으로 만들 수 있다.</li><li>이는 human-friendly 한 설명을 할 수 있다.</li></ul></li><li>fidelity measure<ul><li>해석 가능한 모델이 블랙박스 모델의 예측과 얼마나 잘 일치하는 지를 평가하는 척도</li><li>이를 이용해 블랙박스 예측을 설명하는데 얼마나 신뢰할 수 있는지를 설명할 수 있다.</li></ul></li></ol><h4 id=단점-1><a href=#%eb%8b%a8%ec%a0%90-1 class=header-anchor></a>단점</h4><ol><li>설명 모델의 복잡도를 사전에 정의해야 한다.<ul><li>Tree의 깊이 등.</li></ul></li><li>설명의 불안정성<ul><li><a class=link href=https://arxiv.org/pdf/1806.08049.pdf target=_blank rel=noopener>논문</a>에서 두 개의 매우 가까운 점에 대한 설명이 시뮬레이션된 환경에서 크게 다르다는 것을 보여주었다.</li><li>샘플링 과정을 반복하면 나오는 탐색은 다를 수 있다.</li><li>불안정하다는 것은 설명을 신뢰하기 어렵다는 뜻.</li></ul></li></ol><h2 id=reference><a href=#reference class=header-anchor></a>Reference</h2><ul><li>XAI 설명 가능한 인공지능, 인공지능을 해부하다</li><li><a class=link href=https://christophm.github.io/interpretable-ml-book/global.html target=_blank rel=noopener>https://christophm.github.io/interpretable-ml-book/global.html</a></li><li><a class=link href=https://www.microsoft.com/en-us/research/uploads/prod/2019/05/Explainable-AI-for-Science-and-Medicine-slides.pdf target=_blank rel=noopener>https://www.microsoft.com/en-us/research/uploads/prod/2019/05/Explainable-AI-for-Science-and-Medicine-slides.pdf</a></li></ul></section><footer class=article-footer><section class=article-tags><a href=/blog/tags/xai/>Xai</a></section><section class=article-copyright><svg class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg>
<span>Licensed under CC BY-NC-SA 4.0</span></section></footer><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous defer></script><script>window.addEventListener("DOMContentLoaded",()=>{renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],ignoredClasses:["gist"]})})</script></article><aside class=related-content--wrapper><h2 class=section-title>Related content</h2><div class=related-content><div class="flex article-list--tile"><article><a href=/blog/p/properties-of-explanations/><div class=article-details><h2 class=article-title>Properties of Explanations</h2></div></a></article><article><a href=/blog/p/feature-based-explanations/><div class=article-details><h2 class=article-title>Feature-Based Explanations</h2></div></a></article><article><a href=/blog/p/types-of-explanatory-methods/><div class=article-details><h2 class=article-title>Types of Explanatory Methods</h2></div></a></article><article><a href=/blog/p/lime-with-code/><div class=article-details><h2 class=article-title>LIME with code</h2></div></a></article><article><a href=/blog/p/pandas%EB%A5%BC-%EC%9D%B4%EC%9A%A9%ED%95%9C-tf-idf-%EA%B5%AC%ED%95%98%EA%B8%B0/><div class=article-details><h2 class=article-title>Pandas를 이용한 tf-idf 구하기</h2></div></a></article></div></div></aside><script src=https://utteranc.es/client.js repo=aiden-jeon/aiden-jeon.github.io issue-term=pathname label=comment crossorigin=anonymous async></script><style>.utterances{max-width:unset}</style><script>let utterancesLoaded=!1;function setUtterancesTheme(e){let t=document.querySelector(".utterances iframe");t&&t.contentWindow.postMessage({type:"set-theme",theme:`github-${e}`},"https://utteranc.es")}addEventListener("message",e=>{if(e.origin!=="https://utteranc.es")return;utterancesLoaded=!0,setUtterancesTheme(document.documentElement.dataset.scheme)}),window.addEventListener("onColorSchemeChange",e=>{if(!utterancesLoaded)return;setUtterancesTheme(e.detail)})</script><footer class=site-footer><section class=copyright>&copy;
2020 -
2024 Aiden's Camp</section><section class=powerby>Built with <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a><br>Theme <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.27.0>Stack</a></b> designed by <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a></section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/blog/ts/main.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>