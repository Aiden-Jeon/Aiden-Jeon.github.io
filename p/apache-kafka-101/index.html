<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content="Apache Kafka 101 Apache Kafka 101\n1. Events Kafka many use cases ⇒ start from event streaming platform Event What is Event? things that have happened combined with the description of what happend ⇒ notification + state eg) IOT Business Process Change User Interaction Microservice Output Notification the element of when-ness that can be used to trigger some other activity State Usually small (less than a megabyte) normally represented in some structured format (JSON, an object serialized with Apache Avro or Protocol Buffers) Key / Value kafka models events as key/value pair Internally: sequence of bytes externally: structured objects represented in language’s type system (JSON, JSON Schema, Avro, or Protobuf) 3. Topics Topic most fundamental unit of Kafka something like a table in a relational database Named container for similar events create different topics to hold different kinds of events filtered and transformed versions of the same kind of event → can duplicate data between topics A topic is a log of events Logs Append only: when writing a new message into a log, it always goes on the end Can only seek by offset, not indexed Immutable: once something has happened, it is difficult to make it un-happen Topics are durable Logs are durable Retention is configurable expire data after it has reached a certain age topic overall reached a certain size Logs on Kafka topics are files stored on disk write on event to a topic, it is durable as it would be of you had written it to any database you ever trusted. 4. Partitioning Kafka: Distributed System no one topic could ever get too big aspire to accommodate too many reads and writes What is Partitioning? takes the single topic log → breaks it into multiple logs → each of which can live on a separate node on cluster need a way of deciding which messages to write to which partition message with no key message with a key Message with no key round-robin among all the topic’s partitions pros) all partitions get an even share of the data cons) don’t preserve any kind of ordering of the input message Message with a key destination partition will be computed from a has of the key output of hash function mode of # of partitions guarantee that messages having same key always land in same partition pros) always in order cons) what if very active key? → a larger and more active partition ⇒ risk is small in practice and manageable 6. Brokers Kafka Brokers Actual Computers Kafka is composed of a network of machines called brokers machines can be an computer, instance, or container running the Kafka process Each broker hosts some set of Kafka partitions handles incoming requests to write new events to those partitions to read events from them handles replication of partitions 7. Replication Copies of data for fault tolerance if we store each partition to one broker → susceptible to failure → we need copy partitions data to several brokers One lead partition and N-1 followers Leader: writes and reads happens Follower: works together to replicate those new writes Automatic process → developer don’t need to worry about it 8. Producers Kafka Producer application using Kafka : Producer and Consumer Producing and Consuming: how to interface with cluster API surface of the producer library is fairly lightweight 9. Consumers Kafka Consumer many consumers read one topic reading does not destroy message Rebalancing processes using same group ID → fairly split data to consumer traditional topic keep ordering guarantee in place sacrifice the ability to scale out consumers 11. Ecosystem Infrastructure doesn’t contribute value directly to customers best case ← provided by community or an infrastructure vendor eg) Kafka Connect Confluent Schema Registry Kafka Streams ksqlDB 12. Kafka Connect Job of Kafka connect the data those other systems to get into Kafka topics data in Kafka topics to get into those system What does Kafka Connect Do? Data integration system and ecosystem a client application External client process; does not run on Brokers if something is not a broker is an producer or and consumer Horizontally scalable Fault-tolerant How Kafka Connect Works "><title>Apache Kafka 101</title>
<link rel=canonical href=https://aiden-jeon.github.io/blog/p/apache-kafka-101/><link rel=stylesheet href=/blog/scss/style.min.663803bebe609202d5b39d848f2d7c2dc8b598a2d879efa079fa88893d29c49c.css><meta property='og:title' content="Apache Kafka 101"><meta property='og:description' content="Apache Kafka 101 Apache Kafka 101\n1. Events Kafka many use cases ⇒ start from event streaming platform Event What is Event? things that have happened combined with the description of what happend ⇒ notification + state eg) IOT Business Process Change User Interaction Microservice Output Notification the element of when-ness that can be used to trigger some other activity State Usually small (less than a megabyte) normally represented in some structured format (JSON, an object serialized with Apache Avro or Protocol Buffers) Key / Value kafka models events as key/value pair Internally: sequence of bytes externally: structured objects represented in language’s type system (JSON, JSON Schema, Avro, or Protobuf) 3. Topics Topic most fundamental unit of Kafka something like a table in a relational database Named container for similar events create different topics to hold different kinds of events filtered and transformed versions of the same kind of event → can duplicate data between topics A topic is a log of events Logs Append only: when writing a new message into a log, it always goes on the end Can only seek by offset, not indexed Immutable: once something has happened, it is difficult to make it un-happen Topics are durable Logs are durable Retention is configurable expire data after it has reached a certain age topic overall reached a certain size Logs on Kafka topics are files stored on disk write on event to a topic, it is durable as it would be of you had written it to any database you ever trusted. 4. Partitioning Kafka: Distributed System no one topic could ever get too big aspire to accommodate too many reads and writes What is Partitioning? takes the single topic log → breaks it into multiple logs → each of which can live on a separate node on cluster need a way of deciding which messages to write to which partition message with no key message with a key Message with no key round-robin among all the topic’s partitions pros) all partitions get an even share of the data cons) don’t preserve any kind of ordering of the input message Message with a key destination partition will be computed from a has of the key output of hash function mode of # of partitions guarantee that messages having same key always land in same partition pros) always in order cons) what if very active key? → a larger and more active partition ⇒ risk is small in practice and manageable 6. Brokers Kafka Brokers Actual Computers Kafka is composed of a network of machines called brokers machines can be an computer, instance, or container running the Kafka process Each broker hosts some set of Kafka partitions handles incoming requests to write new events to those partitions to read events from them handles replication of partitions 7. Replication Copies of data for fault tolerance if we store each partition to one broker → susceptible to failure → we need copy partitions data to several brokers One lead partition and N-1 followers Leader: writes and reads happens Follower: works together to replicate those new writes Automatic process → developer don’t need to worry about it 8. Producers Kafka Producer application using Kafka : Producer and Consumer Producing and Consuming: how to interface with cluster API surface of the producer library is fairly lightweight 9. Consumers Kafka Consumer many consumers read one topic reading does not destroy message Rebalancing processes using same group ID → fairly split data to consumer traditional topic keep ordering guarantee in place sacrifice the ability to scale out consumers 11. Ecosystem Infrastructure doesn’t contribute value directly to customers best case ← provided by community or an infrastructure vendor eg) Kafka Connect Confluent Schema Registry Kafka Streams ksqlDB 12. Kafka Connect Job of Kafka connect the data those other systems to get into Kafka topics data in Kafka topics to get into those system What does Kafka Connect Do? Data integration system and ecosystem a client application External client process; does not run on Brokers if something is not a broker is an producer or and consumer Horizontally scalable Fault-tolerant How Kafka Connect Works "><meta property='og:url' content='https://aiden-jeon.github.io/blog/p/apache-kafka-101/'><meta property='og:site_name' content="Aiden's Camp"><meta property='og:type' content='article'><meta property='article:section' content='Post'><meta property='article:tag' content='kafka'><meta property='article:published_time' content='2022-12-06T00:00:00+00:00'><meta property='article:modified_time' content='2022-12-06T00:00:00+00:00'><meta name=twitter:title content="Apache Kafka 101"><meta name=twitter:description content="Apache Kafka 101 Apache Kafka 101\n1. Events Kafka many use cases ⇒ start from event streaming platform Event What is Event? things that have happened combined with the description of what happend ⇒ notification + state eg) IOT Business Process Change User Interaction Microservice Output Notification the element of when-ness that can be used to trigger some other activity State Usually small (less than a megabyte) normally represented in some structured format (JSON, an object serialized with Apache Avro or Protocol Buffers) Key / Value kafka models events as key/value pair Internally: sequence of bytes externally: structured objects represented in language’s type system (JSON, JSON Schema, Avro, or Protobuf) 3. Topics Topic most fundamental unit of Kafka something like a table in a relational database Named container for similar events create different topics to hold different kinds of events filtered and transformed versions of the same kind of event → can duplicate data between topics A topic is a log of events Logs Append only: when writing a new message into a log, it always goes on the end Can only seek by offset, not indexed Immutable: once something has happened, it is difficult to make it un-happen Topics are durable Logs are durable Retention is configurable expire data after it has reached a certain age topic overall reached a certain size Logs on Kafka topics are files stored on disk write on event to a topic, it is durable as it would be of you had written it to any database you ever trusted. 4. Partitioning Kafka: Distributed System no one topic could ever get too big aspire to accommodate too many reads and writes What is Partitioning? takes the single topic log → breaks it into multiple logs → each of which can live on a separate node on cluster need a way of deciding which messages to write to which partition message with no key message with a key Message with no key round-robin among all the topic’s partitions pros) all partitions get an even share of the data cons) don’t preserve any kind of ordering of the input message Message with a key destination partition will be computed from a has of the key output of hash function mode of # of partitions guarantee that messages having same key always land in same partition pros) always in order cons) what if very active key? → a larger and more active partition ⇒ risk is small in practice and manageable 6. Brokers Kafka Brokers Actual Computers Kafka is composed of a network of machines called brokers machines can be an computer, instance, or container running the Kafka process Each broker hosts some set of Kafka partitions handles incoming requests to write new events to those partitions to read events from them handles replication of partitions 7. Replication Copies of data for fault tolerance if we store each partition to one broker → susceptible to failure → we need copy partitions data to several brokers One lead partition and N-1 followers Leader: writes and reads happens Follower: works together to replicate those new writes Automatic process → developer don’t need to worry about it 8. Producers Kafka Producer application using Kafka : Producer and Consumer Producing and Consuming: how to interface with cluster API surface of the producer library is fairly lightweight 9. Consumers Kafka Consumer many consumers read one topic reading does not destroy message Rebalancing processes using same group ID → fairly split data to consumer traditional topic keep ordering guarantee in place sacrifice the ability to scale out consumers 11. Ecosystem Infrastructure doesn’t contribute value directly to customers best case ← provided by community or an infrastructure vendor eg) Kafka Connect Confluent Schema Registry Kafka Streams ksqlDB 12. Kafka Connect Job of Kafka connect the data those other systems to get into Kafka topics data in Kafka topics to get into those system What does Kafka Connect Do? Data integration system and ecosystem a client application External client process; does not run on Brokers if something is not a broker is an producer or and consumer Horizontally scalable Fault-tolerant How Kafka Connect Works "><link rel="shortcut icon" href=/blog/icons/favicon.ico><script async src="https://www.googletagmanager.com/gtag/js?id=G-419F58RW9W"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-419F58RW9W")}</script></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label="Toggle Menu">
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/blog/><img src=/blog/imgs/avatar_hu6933059792947527008.png width=300 height=300 class=site-logo loading=lazy alt=Avatar>
</a><span class=emoji>🔥</span></figure><div class=site-meta><h1 class=site-name><a href=/blog>Aiden's Camp</a></h1><h2 class=site-description>Welcome to Aiden's Camp</h2></div></header><ol class=menu-social><li><a href=https://github.com/Aiden-Jeon target=_blank title=GitHub rel=me><svg class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li><li><a href=https://www.linkedin.com/in/jongseob-jeon/ target=_blank title=Linkedin rel=me><svg fill="#000" height="800" width="800" id="Layer_1" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 310 310"><g id="XMLID_801_"><path id="XMLID_802_" d="M72.16 99.73H9.927c-2.762.0-5 2.239-5 5v199.928c0 2.762 2.238 5 5 5H72.16c2.762.0 5-2.238 5-5V104.73c0-2.76100000000001-2.238-5-5-5z"/><path id="XMLID_803_" d="M41.066.341C18.422.341.0 18.743.0 41.362.0 63.991 18.422 82.4 41.066 82.4c22.626.0 41.033-18.41 41.033-41.038C82.1 18.743 63.692.341 41.066.341z"/><path id="XMLID_804_" d="M230.454 94.761c-24.995.0-43.472 10.745-54.679 22.954V104.73c0-2.761-2.238-5-5-5h-59.599c-2.762.0-5 2.239-5 5v199.928c0 2.762 2.238 5 5 5h62.097c2.762.0 5-2.238 5-5V205.74c0-33.333 9.054-46.319 32.29-46.319 25.306.0 27.317 20.818 27.317 48.034v97.204c0 2.762 2.238 5 5 5H305c2.762.0 5-2.238 5-5V194.995C310 145.43 300.549 94.761 230.454 94.761z"/></g></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/blog/><svg class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>Home</span></a></li><li><a href=/blog/categories><svg class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg>
<span>Categories</span></a></li><li><a href=/blog/tags><svg class="icon icon-tabler icon-tabler-tag" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11 3l9 9a1.5 1.5.0 010 2l-6 6a1.5 1.5.0 01-2 0L3 11V7a4 4 0 014-4h4"/><circle cx="9" cy="9" r="2"/></svg>
<span>Tags</span></a></li><li><a href=/blog/links/><svg class="icon icon-tabler icon-tabler-link" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M10 14a3.5 3.5.0 005 0l4-4a3.5 3.5.0 00-5-5l-.5.5"/><path d="M14 10a3.5 3.5.0 00-5 0l-4 4a3.5 3.5.0 005 5l.5-.5"/></svg>
<span>Links</span></a></li><li><a href=/blog/search/><svg class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
<span>Search</span></a></li><li><a href=/blog/archives/><svg class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg>
<span>Archives</span></a></li><li class=menu-bottom-section><ol class=menu><li id=dark-mode-toggle><svg class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>Dark Mode</span></li></ol></li></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">Table of contents</h2><div class=widget--toc><nav id=TableOfContents><ul><li><a href=#1-events>1. Events</a><ul><li><a href=#kafka>Kafka</a></li><li><a href=#event>Event</a></li><li><a href=#key--value>Key / Value</a></li></ul></li><li><a href=#3-topics>3. Topics</a><ul><li><a href=#topic>Topic</a></li><li><a href=#named-container-for-similar-events>Named container for similar events</a></li><li><a href=#a-topic-is-a-log-of-events>A topic is a log of events</a></li><li><a href=#topics-are-durable>Topics are durable</a></li></ul></li><li><a href=#4-partitioning>4. Partitioning</a><ul><li><a href=#what-is-partitioning>What is Partitioning?</a></li><li><a href=#message-with-no-key>Message with no key</a></li><li><a href=#message-with-a-key>Message with a key</a></li></ul></li><li><a href=#6-brokers>6. Brokers</a><ul><li><a href=#kafka-brokers>Kafka Brokers</a></li></ul></li><li><a href=#7-replication>7. Replication</a></li><li><a href=#8-producers>8. Producers</a><ul><li><a href=#kafka-producer>Kafka Producer</a></li></ul></li><li><a href=#9-consumers>9. Consumers</a><ul><li><a href=#kafka-consumer>Kafka Consumer</a></li></ul></li><li><a href=#11-ecosystem>11. Ecosystem</a></li><li><a href=#12-kafka-connect>12. Kafka Connect</a><ul><li><a href=#what-does-kafka-connect-do>What does Kafka Connect Do?</a></li><li><a href=#how-kafka-connect-works>How Kafka Connect Works</a></li><li><a href=#benefits-of-kafka-connect>Benefits of Kafka Connect</a></li></ul></li><li><a href=#14-confluent-schema-registry>14. Confluent Schema Registry</a><ul><li><a href=#what-is-schema-registry>What is Schema Registry</a></li></ul></li><li><a href=#16-kafka-stream>16. Kafka Stream</a><ul><li><a href=#kafka-stream>Kafka Stream</a></li></ul></li></ul></nav></div></section></aside><main class="main full-width"><article class=main-article><header class=article-header><div class=article-details><header class=article-category><a href=/blog/categories/mlops/>Mlops</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/blog/p/apache-kafka-101/>Apache Kafka 101</a></h2></div><footer class=article-time><div><svg class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published>Dec 06, 2022</time></div><div><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<time class=article-time--reading>5 minute read</time></div></footer></div></header><section class=article-content><h1 id=apache-kafka-101><a href=#apache-kafka-101 class=header-anchor></a>Apache Kafka 101</h1><p><a class=link href=https://developer.confluent.io/learn-kafka/apache-kafka/ target=_blank rel=noopener>Apache Kafka 101</a></p><h2 id=1-events><a href=#1-events class=header-anchor></a>1. Events</h2><h3 id=kafka><a href=#kafka class=header-anchor></a>Kafka</h3><ul><li>many use cases</li><li>⇒ start from event streaming platform</li></ul><h3 id=event><a href=#event class=header-anchor></a>Event</h3><ul><li>What is Event?<ul><li>things that have happened combined with the description of what happend</li><li>⇒ notification + state</li></ul></li><li>eg)<ul><li>IOT</li><li>Business Process Change</li><li>User Interaction</li><li>Microservice Output</li></ul></li><li>Notification<ul><li>the element of when-ness that can be used to trigger some other activity</li></ul></li><li>State<ul><li>Usually small (less than a megabyte)</li><li>normally represented in some structured format (JSON, an object serialized with Apache Avro or Protocol Buffers)</li></ul></li></ul><h3 id=key--value><a href=#key--value class=header-anchor></a>Key / Value</h3><ul><li>kafka models events as key/value pair</li><li>Internally: sequence of bytes</li><li>externally: structured objects represented in language’s type system<ul><li>(JSON, JSON Schema, Avro, or Protobuf)</li></ul></li></ul><h2 id=3-topics><a href=#3-topics class=header-anchor></a>3. Topics</h2><h3 id=topic><a href=#topic class=header-anchor></a>Topic</h3><ul><li>most fundamental unit of Kafka</li><li>something like a table in a relational database</li></ul><h3 id=named-container-for-similar-events><a href=#named-container-for-similar-events class=header-anchor></a>Named container for similar events</h3><ul><li>create different topics to hold<ul><li>different kinds of events</li><li>filtered and transformed versions of the same kind of event<ul><li>→ can duplicate data between topics</li></ul></li></ul></li></ul><h3 id=a-topic-is-a-log-of-events><a href=#a-topic-is-a-log-of-events class=header-anchor></a>A topic is a log of events</h3><ul><li>Logs<ol><li>Append only: when writing a new message into a log, it always goes on the end</li><li>Can only seek by offset, not indexed</li><li>Immutable: once something has happened, it is difficult to make it un-happen</li></ol></li></ul><h3 id=topics-are-durable><a href=#topics-are-durable class=header-anchor></a>Topics are durable</h3><ul><li>Logs are durable</li><li>Retention is configurable<ul><li>expire data after it has reached a certain age</li><li>topic overall reached a certain size</li></ul></li><li>Logs on Kafka topics are files stored on disk<ul><li>write on event to a topic, it is durable as it would be of you had written it to any database you ever trusted.</li></ul></li></ul><h2 id=4-partitioning><a href=#4-partitioning class=header-anchor></a>4. Partitioning</h2><ul><li>Kafka: Distributed System<ul><li>no one topic could ever get too big</li><li>aspire to accommodate too many reads and writes</li></ul></li></ul><h3 id=what-is-partitioning><a href=#what-is-partitioning class=header-anchor></a>What is Partitioning?</h3><ul><li>takes the single topic log<ul><li>→ breaks it into multiple logs</li><li>→ each of which can live on a separate node on cluster</li></ul></li><li>need a way of deciding which messages to write to which partition<ul><li>message with no key</li><li>message with a key</li></ul></li></ul><h3 id=message-with-no-key><a href=#message-with-no-key class=header-anchor></a>Message with no key</h3><ul><li>round-robin among all the topic’s partitions</li><li>pros) all partitions get an even share of the data</li><li>cons) don’t preserve any kind of ordering of the input message</li></ul><h3 id=message-with-a-key><a href=#message-with-a-key class=header-anchor></a>Message with a key</h3><ul><li>destination partition will be computed from a has of the key<ul><li>output of hash function mode of # of partitions</li><li>guarantee that messages having same key always land in same partition</li></ul></li><li>pros) always in order</li><li>cons) what if very active key? → a larger and more active partition<ul><li>⇒ risk is small in practice and manageable</li></ul></li></ul><h2 id=6-brokers><a href=#6-brokers class=header-anchor></a>6. Brokers</h2><h3 id=kafka-brokers><a href=#kafka-brokers class=header-anchor></a>Kafka Brokers</h3><ul><li>Actual Computers</li><li>Kafka is composed of a network of machines called brokers<ul><li>machines can be an computer, instance, or container running the Kafka process</li></ul></li><li>Each broker hosts some set of Kafka partitions<ul><li>handles incoming requests<ul><li>to write new events to those partitions</li><li>to read events from them</li></ul></li><li>handles replication of partitions</li></ul></li></ul><h2 id=7-replication><a href=#7-replication class=header-anchor></a>7. Replication</h2><ul><li>Copies of data for fault tolerance<ul><li>if we store each partition to one broker
→ susceptible to failure
→ we need copy partitions data to several brokers</li></ul></li><li>One lead partition and N-1 followers<ul><li>Leader: writes and reads happens</li><li>Follower: works together to replicate those new writes</li></ul></li><li>Automatic process → developer don’t need to worry about it</li></ul><h2 id=8-producers><a href=#8-producers class=header-anchor></a>8. Producers</h2><h3 id=kafka-producer><a href=#kafka-producer class=header-anchor></a>Kafka Producer</h3><ul><li>application using Kafka : Producer and Consumer</li><li>Producing and Consuming: how to interface with cluster</li><li>API surface of the producer library is fairly lightweight</li></ul><h2 id=9-consumers><a href=#9-consumers class=header-anchor></a>9. Consumers</h2><h3 id=kafka-consumer><a href=#kafka-consumer class=header-anchor></a>Kafka Consumer</h3><ul><li>many consumers read one topic<ul><li>reading does not destroy message</li></ul></li><li>Rebalancing processes<ul><li>using same group ID → fairly split data to consumer</li></ul></li><li>traditional topic<ul><li>keep ordering guarantee in place</li><li>sacrifice the ability to scale out consumers</li></ul></li></ul><h2 id=11-ecosystem><a href=#11-ecosystem class=header-anchor></a>11. Ecosystem</h2><ul><li>Infrastructure<ul><li>doesn’t contribute value directly to customers</li><li>best case ← provided by community or an infrastructure vendor</li></ul></li><li>eg)<ul><li>Kafka Connect</li><li>Confluent Schema Registry</li><li>Kafka Streams</li><li>ksqlDB</li></ul></li></ul><h2 id=12-kafka-connect><a href=#12-kafka-connect class=header-anchor></a>12. Kafka Connect</h2><ul><li>Job of Kafka connect<ul><li>the data those other systems to get into Kafka topics</li><li>data in Kafka topics to get into those system</li></ul></li></ul><h3 id=what-does-kafka-connect-do><a href=#what-does-kafka-connect-do class=header-anchor></a>What does Kafka Connect Do?</h3><ul><li>Data integration system and ecosystem</li><li>a client application<ul><li>External client process; does not run on Brokers<ul><li><em>if something is not a broker is an producer or and consumer</em></li></ul></li><li>Horizontally scalable</li><li>Fault-tolerant</li></ul></li></ul><h3 id=how-kafka-connect-works><a href=#how-kafka-connect-works class=header-anchor></a>How Kafka Connect Works</h3><p><img src=/imgs/kafka/kafka-connect-workflow.png loading=lazy alt="Kafka Connect Workflow"></p><ul><li>Connect worker runs one or more connectors</li><li>Connectors<ul><li>pluggable software component</li><li>interfacing with the external system</li><li>Also exist as runtime entities</li></ul></li><li>Source connector (acts as Producer)<ul><li>reads data from and external system and produces it to a Kafka topi</li></ul></li><li>Sink connector (acts as Consumer)<ul><li>subscribes to one or more Kafka topics and writes the messages it reads to an external system</li></ul></li></ul><h3 id=benefits-of-kafka-connect><a href=#benefits-of-kafka-connect class=header-anchor></a>Benefits of Kafka Connect</h3><ul><li>large ecosystem of connectors</li></ul><h2 id=14-confluent-schema-registry><a href=#14-confluent-schema-registry class=header-anchor></a>14. Confluent Schema Registry</h2><ul><li>To solve two problems<ol><li>New consumers of existing topics will emerge<ul><li>→ need to understand the format of the message in the topic</li></ul></li><li>The format of those message will evolve as the business evolves<ul><li>→ the schemas of domain objects is a constantly moving target</li><li>must have a way of agreeing on the schema of messages in any given topic</li></ul></li></ol></li></ul><h3 id=what-is-schema-registry><a href=#what-is-schema-registry class=header-anchor></a>What is Schema Registry</h3><ul><li>Sever Process external to Kafka brokers</li><li>Job: maintain a <em>database</em> of <em>schemas</em><ul><li>schema: that have been written into topics in the cluster for which it is responsible.</li><li>database: internal Kafka topic and cached in Schema Registry for lower latency access</li></ul></li><li>Consumer/Producer API Component<ul><li>Process<ol><li>calls on API at the Schema Registry REST endpoint</li><li>presents the schema of the new message</li></ol></li><li>Response<ul><li>Produce side<ul><li>if same as last message → <strong>produce succeed</strong></li><li>if different from last message<ul><li>but matches the compatibility rules defined for the topic → <strong>produce succeed</strong></li><li>violates compatibility rules → <strong>produce fail</strong> in a way that the application code can detect</li></ul></li></ul></li><li>Consume side<ul><li>Consumer API prevents incompatible message from being consumed</li></ul></li></ul></li></ul></li><li>Support Formats<ul><li>JSON Schema</li><li>Avro</li><li>Protocol Buffers</li></ul></li></ul><h2 id=16-kafka-stream><a href=#16-kafka-stream class=header-anchor></a>16. Kafka Stream</h2><ul><li>Consumer tend to grow in complexity<ul><li>started from <em>stateless</em> transformation (masking, changing format)</li><li>→being complexity → stateful</li></ul></li><li>state<ul><li>memory allocated in program’s heap</li><li>→ fault-tolerant liability</li></ul></li></ul><h3 id=kafka-stream><a href=#kafka-stream class=header-anchor></a>Kafka Stream</h3><ul><li>Functional Java API</li><li>Filtering, grouping, aggregating, joining, and more</li><li>Scalable, fault-tolerant state management</li><li>Integrates within your services as a library</li><li>Runs in the context of your application</li><li>Does not require special infrastructure</li></ul></section><footer class=article-footer><section class=article-tags><a href=/blog/tags/kafka/>Kafka</a></section><section class=article-copyright><svg class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg>
<span>Licensed under CC BY-NC-SA 4.0</span></section></footer><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous defer></script><script>window.addEventListener("DOMContentLoaded",()=>{renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],ignoredClasses:["gist"]})})</script></article><aside class=related-content--wrapper><h2 class=section-title>Related content</h2><div class=related-content><div class="flex article-list--tile"><article><a href=/blog/p/kafka-setup/><div class=article-details><h2 class=article-title>Kafka Setup</h2></div></a></article><article><a href=/blog/p/chapter-9.-continual-learning-and-test-in-production/><div class=article-details><h2 class=article-title>Chapter 9. Continual Learning and Test in Production</h2></div></a></article><article><a href=/blog/p/chapter-8.-data-distribution-shifts-and-monitoring/><div class=article-details><h2 class=article-title>Chapter 8. Data Distribution Shifts and Monitoring</h2></div></a></article><article><a href=/blog/p/chapter-7.-model-deployment-and-prediction-service/><div class=article-details><h2 class=article-title>Chapter 7. Model Deployment and Prediction Service</h2></div></a></article><article><a href=/blog/p/chapter-3.-data-engineer-fundamentals/><div class=article-details><h2 class=article-title>Chapter 3. Data Engineer Fundamentals</h2></div></a></article></div></div></aside><script src=https://utteranc.es/client.js repo=aiden-jeon/aiden-jeon.github.io issue-term=pathname label=comment crossorigin=anonymous async></script><style>.utterances{max-width:unset}</style><script>let utterancesLoaded=!1;function setUtterancesTheme(e){let t=document.querySelector(".utterances iframe");t&&t.contentWindow.postMessage({type:"set-theme",theme:`github-${e}`},"https://utteranc.es")}addEventListener("message",e=>{if(e.origin!=="https://utteranc.es")return;utterancesLoaded=!0,setUtterancesTheme(document.documentElement.dataset.scheme)}),window.addEventListener("onColorSchemeChange",e=>{if(!utterancesLoaded)return;setUtterancesTheme(e.detail)})</script><footer class=site-footer><section class=copyright>&copy;
2020 -
2024 Aiden's Camp</section><section class=powerby>Built with <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a><br>Theme <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.27.0>Stack</a></b> designed by <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a></section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/blog/ts/main.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>